{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "dTwFSj2qoCJ-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "-38GDSvSoCKA",
    "outputId": "05d6bf4a-2325-4100-c760-5c9a2283e280"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length  sepal width  petal length  petal width           class\n",
       "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
       "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
       "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
       "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
       "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
       "..            ...          ...           ...          ...             ...\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/iris.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HqeNcxyboCKB",
    "outputId": "e1985a3e-8021-450b-f76d-3ec50231f0a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsores = df.iloc[:, :4].values\n",
    "previsores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SRJmczlloCKB",
    "outputId": "d964a647-4b53-4777-db0c-35a1eaa93669"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = df.iloc[:, -1].values\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzOHGt_eoCKC"
   },
   "source": [
    "Como a rede neural não entende variavel categorica, temos que converter as possiveis classes em números:\n",
    "      \n",
    "      - 0 = Iris-setosa;\n",
    "      - 1 = Iris-versicolor;\n",
    "      - 2 = Iris-virginica;\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uDTFStF_oCKC",
    "outputId": "af31669d-ea23-4b14-9992-bc3a73e92111"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "labelenconder = LabelEncoder()\n",
    "classes = labelenconder.fit_transform(classes)\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwGsRALqoCKC"
   },
   "source": [
    "Transformando o dado de 1 dimensão para 3, seguindo a saída da rede neural\n",
    " - 1 0 0 = Iris-setosa;\n",
    " - 0 1 0 = Iris-versicolor;\n",
    " - 0 0 1 = Iris-virginica;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oW6vLQTKoCKD",
    "outputId": "49956c36-74de-4752-a9d5-36439d49ab95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_dummy = to_categorical(classes)\n",
    "classes_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "mt9hbCEVoCKD"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "PQrXY_ldoCKD"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(previsores, classes_dummy, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "sVHf-tZRoCKE"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "pFlVJQTkoCKF"
   },
   "outputs": [],
   "source": [
    "def createNetwork():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=10, activation=\"relu\", input_dim=4))\n",
    "    model.add(Dense(units=3, activation=\"softmax\"))\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model_json = model.to_json()\n",
    "    with open(\"model_iris.json\",\"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "GhbEI2HRoCKG"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = KerasClassifier(build_fn=createNetwork, batch_size=5, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GTB6GAgHoCKG",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = cross_val_score(estimator=model, X=previsores, y=classes, cv=10, scoring=\"accuracy\")\n",
    "average = results.mean()\n",
    "print(average)\n",
    "desvio_padrao = results.std()\n",
    "print(desvio_padrao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y-WpHXs2oCKG",
    "outputId": "a00a28d3-bb2b-4f47-dabc-ebe5fb18762d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 3.6289 - accuracy: 0.3689\n",
      "Epoch 2/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 3.3835 - accuracy: 0.3254\n",
      "Epoch 3/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 2.9358 - accuracy: 0.3330\n",
      "Epoch 4/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 2.6517 - accuracy: 0.3143\n",
      "Epoch 5/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 2.4169 - accuracy: 0.2672\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.7410 - accuracy: 0.3460\n",
      "Epoch 7/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.5251 - accuracy: 0.3283\n",
      "Epoch 8/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.2012 - accuracy: 0.3198\n",
      "Epoch 9/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0524 - accuracy: 0.3478\n",
      "Epoch 10/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.9130 - accuracy: 0.4417\n",
      "Epoch 11/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8471 - accuracy: 0.5745\n",
      "Epoch 12/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8248 - accuracy: 0.5695\n",
      "Epoch 13/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8054 - accuracy: 0.6938\n",
      "Epoch 14/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7944 - accuracy: 0.6618\n",
      "Epoch 15/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7933 - accuracy: 0.6893\n",
      "Epoch 16/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7244 - accuracy: 0.7525\n",
      "Epoch 17/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7188 - accuracy: 0.7515\n",
      "Epoch 18/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7084 - accuracy: 0.7196\n",
      "Epoch 19/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.7198\n",
      "Epoch 20/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6981 - accuracy: 0.7342\n",
      "Epoch 21/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7063 - accuracy: 0.6532\n",
      "Epoch 22/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6331 - accuracy: 0.7951\n",
      "Epoch 23/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6324 - accuracy: 0.7184\n",
      "Epoch 24/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6113 - accuracy: 0.7678\n",
      "Epoch 25/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6185 - accuracy: 0.7963\n",
      "Epoch 26/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5823 - accuracy: 0.8134\n",
      "Epoch 27/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5700 - accuracy: 0.8028\n",
      "Epoch 28/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5808 - accuracy: 0.7608\n",
      "Epoch 29/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5525 - accuracy: 0.8543\n",
      "Epoch 30/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5616 - accuracy: 0.7976\n",
      "Epoch 31/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5413 - accuracy: 0.8164\n",
      "Epoch 32/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.8680\n",
      "Epoch 33/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5274 - accuracy: 0.8590\n",
      "Epoch 34/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5174 - accuracy: 0.8374\n",
      "Epoch 35/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5334 - accuracy: 0.8147\n",
      "Epoch 36/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.8722\n",
      "Epoch 37/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.8700\n",
      "Epoch 38/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4796 - accuracy: 0.8950\n",
      "Epoch 39/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.8687\n",
      "Epoch 40/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.9066\n",
      "Epoch 41/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4566 - accuracy: 0.8803\n",
      "Epoch 42/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.8735\n",
      "Epoch 43/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.9147\n",
      "Epoch 44/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.9230\n",
      "Epoch 45/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4162 - accuracy: 0.8928\n",
      "Epoch 46/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4365 - accuracy: 0.9043\n",
      "Epoch 47/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.9002\n",
      "Epoch 48/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4081 - accuracy: 0.9251\n",
      "Epoch 49/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4321 - accuracy: 0.9044\n",
      "Epoch 50/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3916 - accuracy: 0.9298\n",
      "Epoch 51/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4107 - accuracy: 0.9091\n",
      "Epoch 52/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4030 - accuracy: 0.9274\n",
      "Epoch 53/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3909 - accuracy: 0.9341\n",
      "Epoch 54/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.9515\n",
      "Epoch 55/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3891 - accuracy: 0.9541\n",
      "Epoch 56/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3637 - accuracy: 0.9581\n",
      "Epoch 57/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3624 - accuracy: 0.9333\n",
      "Epoch 58/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3709 - accuracy: 0.9622\n",
      "Epoch 59/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3641 - accuracy: 0.9581\n",
      "Epoch 60/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3617 - accuracy: 0.9487\n",
      "Epoch 61/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.9661\n",
      "Epoch 62/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3977 - accuracy: 0.9104\n",
      "Epoch 63/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3500 - accuracy: 0.9438\n",
      "Epoch 64/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3554 - accuracy: 0.9413\n",
      "Epoch 65/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3251 - accuracy: 0.9809\n",
      "Epoch 66/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3070 - accuracy: 0.9743\n",
      "Epoch 67/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3010 - accuracy: 0.9670\n",
      "Epoch 68/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3430 - accuracy: 0.9756\n",
      "Epoch 69/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.9749\n",
      "Epoch 70/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.9593\n",
      "Epoch 71/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.9740\n",
      "Epoch 72/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3161 - accuracy: 0.9627\n",
      "Epoch 73/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3073 - accuracy: 0.9782\n",
      "Epoch 74/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2923 - accuracy: 0.9699\n",
      "Epoch 75/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3132 - accuracy: 0.9684\n",
      "Epoch 76/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2901 - accuracy: 0.9615\n",
      "Epoch 77/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2742 - accuracy: 0.9806\n",
      "Epoch 78/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3216 - accuracy: 0.9435\n",
      "Epoch 79/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2793 - accuracy: 0.9725\n",
      "Epoch 80/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2910 - accuracy: 0.9605\n",
      "Epoch 81/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2578 - accuracy: 0.9711\n",
      "Epoch 82/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2657 - accuracy: 0.9629\n",
      "Epoch 83/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2765 - accuracy: 0.9677\n",
      "Epoch 84/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2719 - accuracy: 0.9860\n",
      "Epoch 85/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2665 - accuracy: 0.9794\n",
      "Epoch 86/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2704 - accuracy: 0.9932\n",
      "Epoch 87/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2397 - accuracy: 0.9798\n",
      "Epoch 88/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2568 - accuracy: 0.9844\n",
      "Epoch 89/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2597 - accuracy: 0.9836\n",
      "Epoch 90/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2390 - accuracy: 0.9701\n",
      "Epoch 91/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2613 - accuracy: 0.9811\n",
      "Epoch 92/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2301 - accuracy: 0.9561\n",
      "Epoch 93/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2327 - accuracy: 0.9579\n",
      "Epoch 94/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2267 - accuracy: 0.9772\n",
      "Epoch 95/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2240 - accuracy: 0.9853\n",
      "Epoch 96/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2119 - accuracy: 0.9787\n",
      "Epoch 97/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2021 - accuracy: 0.9917\n",
      "Epoch 98/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2386 - accuracy: 0.9661\n",
      "Epoch 99/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2352 - accuracy: 0.9779\n",
      "Epoch 100/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2013 - accuracy: 0.9798\n",
      "Epoch 101/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2175 - accuracy: 0.9724\n",
      "Epoch 102/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2160 - accuracy: 0.9580\n",
      "Epoch 103/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2286 - accuracy: 0.9827\n",
      "Epoch 104/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2069 - accuracy: 0.9770\n",
      "Epoch 105/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2178 - accuracy: 0.9684\n",
      "Epoch 106/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.2295 - accuracy: 0.9712\n",
      "Epoch 107/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2124 - accuracy: 0.9649\n",
      "Epoch 108/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.9840\n",
      "Epoch 109/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1890 - accuracy: 0.9819\n",
      "Epoch 110/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1959 - accuracy: 0.9869\n",
      "Epoch 111/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1915 - accuracy: 0.9726\n",
      "Epoch 112/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1887 - accuracy: 0.9826\n",
      "Epoch 113/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2226 - accuracy: 0.9473\n",
      "Epoch 114/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2011 - accuracy: 0.9605\n",
      "Epoch 115/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2027 - accuracy: 0.9618\n",
      "Epoch 116/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2094 - accuracy: 0.9584\n",
      "Epoch 117/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.9757\n",
      "Epoch 118/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1689 - accuracy: 0.9853\n",
      "Epoch 119/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1639 - accuracy: 0.9819\n",
      "Epoch 120/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1966 - accuracy: 0.9736\n",
      "Epoch 121/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1749 - accuracy: 0.9851\n",
      "Epoch 122/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1964 - accuracy: 0.9518\n",
      "Epoch 123/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1588 - accuracy: 0.9899\n",
      "Epoch 124/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1746 - accuracy: 0.9868\n",
      "Epoch 125/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1612 - accuracy: 0.9860\n",
      "Epoch 126/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.9678\n",
      "Epoch 127/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9732\n",
      "Epoch 128/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1502 - accuracy: 0.9906\n",
      "Epoch 129/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.9703\n",
      "Epoch 130/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1691 - accuracy: 0.9665\n",
      "Epoch 131/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1593 - accuracy: 0.9613\n",
      "Epoch 132/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1752 - accuracy: 0.9525\n",
      "Epoch 133/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1602 - accuracy: 0.9762\n",
      "Epoch 134/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1422 - accuracy: 0.9933\n",
      "Epoch 135/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1519 - accuracy: 0.9813\n",
      "Epoch 136/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1589 - accuracy: 0.9592\n",
      "Epoch 137/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1435 - accuracy: 0.9702\n",
      "Epoch 138/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1463 - accuracy: 0.9747\n",
      "Epoch 139/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1439 - accuracy: 0.9670\n",
      "Epoch 140/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1239 - accuracy: 0.9847\n",
      "Epoch 141/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1644 - accuracy: 0.9689\n",
      "Epoch 142/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1556 - accuracy: 0.9908\n",
      "Epoch 143/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1452 - accuracy: 0.9633\n",
      "Epoch 144/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1706 - accuracy: 0.9617\n",
      "Epoch 145/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1410 - accuracy: 0.9810\n",
      "Epoch 146/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1492 - accuracy: 0.9866\n",
      "Epoch 147/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1425 - accuracy: 0.9770\n",
      "Epoch 148/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1352 - accuracy: 0.9789\n",
      "Epoch 149/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1478 - accuracy: 0.9681\n",
      "Epoch 150/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1312 - accuracy: 0.9792\n",
      "Epoch 151/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1415 - accuracy: 0.9702\n",
      "Epoch 152/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1337 - accuracy: 0.9811\n",
      "Epoch 153/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1518 - accuracy: 0.9631\n",
      "Epoch 154/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1406 - accuracy: 0.9715\n",
      "Epoch 155/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1280 - accuracy: 0.9791\n",
      "Epoch 156/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1393 - accuracy: 0.9793\n",
      "Epoch 157/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1197 - accuracy: 0.9873\n",
      "Epoch 158/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1134 - accuracy: 0.9873\n",
      "Epoch 159/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1172 - accuracy: 0.9932\n",
      "Epoch 160/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1235 - accuracy: 0.9880\n",
      "Epoch 161/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1247 - accuracy: 0.9970\n",
      "Epoch 162/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1364 - accuracy: 0.9839\n",
      "Epoch 163/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1581 - accuracy: 0.9733\n",
      "Epoch 164/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1104 - accuracy: 0.9850\n",
      "Epoch 165/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1184 - accuracy: 0.9880\n",
      "Epoch 166/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1410 - accuracy: 0.9780\n",
      "Epoch 167/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1333 - accuracy: 0.9872\n",
      "Epoch 168/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1324 - accuracy: 0.9923\n",
      "Epoch 169/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1272 - accuracy: 0.9890\n",
      "Epoch 170/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1152 - accuracy: 0.9832\n",
      "Epoch 171/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9933\n",
      "Epoch 172/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1310 - accuracy: 0.9974\n",
      "Epoch 173/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1353 - accuracy: 0.9696\n",
      "Epoch 174/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1117 - accuracy: 0.9932\n",
      "Epoch 175/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1265 - accuracy: 0.9687\n",
      "Epoch 176/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.9933\n",
      "Epoch 177/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1233 - accuracy: 0.9881\n",
      "Epoch 178/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1130 - accuracy: 0.9801\n",
      "Epoch 179/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1277 - accuracy: 0.9652\n",
      "Epoch 180/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1296 - accuracy: 0.9860\n",
      "Epoch 181/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1124 - accuracy: 0.9933\n",
      "Epoch 182/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1236 - accuracy: 0.9730\n",
      "Epoch 183/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1100 - accuracy: 0.9705\n",
      "Epoch 184/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1169 - accuracy: 0.9712\n",
      "Epoch 185/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1028 - accuracy: 0.9954\n",
      "Epoch 186/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1462 - accuracy: 0.9605\n",
      "Epoch 187/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1108 - accuracy: 0.9842\n",
      "Epoch 188/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1344 - accuracy: 0.9638\n",
      "Epoch 189/200\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1206 - accuracy: 0.9694\n",
      "Epoch 190/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1190 - accuracy: 0.9731\n",
      "Epoch 191/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1101 - accuracy: 0.9809\n",
      "Epoch 192/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1154 - accuracy: 0.9859\n",
      "Epoch 193/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0868 - accuracy: 0.9782\n",
      "Epoch 194/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1024 - accuracy: 0.9880\n",
      "Epoch 195/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0983 - accuracy: 0.9793\n",
      "Epoch 196/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0799 - accuracy: 0.9937\n",
      "Epoch 197/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0922 - accuracy: 0.9789\n",
      "Epoch 198/200\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1022 - accuracy: 0.9784\n",
      "Epoch 199/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1130 - accuracy: 0.9854\n",
      "Epoch 200/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.0921 - accuracy: 0.9964\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=10, activation=\"relu\", input_dim=4))\n",
    "model.add(Dense(units=3, activation=\"softmax\"))\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(previsores, classes_dummy, batch_size=10, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "Tj89o7c9oCKH"
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "#salvando as configuracoes\n",
    "with open(\"model_iris.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "#salvando os pesos\n",
    "model.save_weights(\"model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v3GaRfCC8D_Z",
    "outputId": "e604cc81-cd1b-47e7-cdb8-d0e38d5fe268"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1040 - accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(previsores, classes_dummy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "6kMkKLIk8PHu"
   },
   "outputs": [],
   "source": [
    "previsoes = model.predict(previsores)\n",
    "previsoes = [np.argmax(t) for t in previsoes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "wmEBDcXD9Z_r"
   },
   "outputs": [],
   "source": [
    "y_test_labed = [np.argmax(t) for t in classes_dummy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AdH8dHO39fXZ",
    "outputId": "23c67764-e511-4413-df1b-bf755e6deba6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50,  0,  0],\n",
       "       [ 0, 48,  1],\n",
       "       [ 0,  2, 49]])"
      ]
     },
     "execution_count": 109,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(previsoes, y_test_labed)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "iris.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
